{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000f05b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import visualization.plots \n",
    "import datasets.control\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from datasets.mnist1d import load_MNIST1D\n",
    "from datasets.mnist import load_MNIST\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b458fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.control import get_mixture_distribution\n",
    "\n",
    "mixture_list = [\n",
    "    # uniform between [-10, -5] and [5, 10]\n",
    "    (\"uniform\",\n",
    "     np.array([-10.0, -5.0]),\n",
    "     np.array([  5.0, 10.0])),\n",
    "\n",
    "    # normal with mean [10, 5] and std [2, 12]\n",
    "    (\"normal\",\n",
    "     np.array([10.0,  5.0]),\n",
    "     np.array([ 2.0, 12.0])),\n",
    "\n",
    "    # normal centered at  0 with unit variance in both dims\n",
    "    (\"normal\",\n",
    "     np.array([0.0, 0.0]),\n",
    "     np.array([1.0, 1.0])),\n",
    "\n",
    "    # normal with mean [3, 6] and std [4, 5]\n",
    "    (\"normal\",\n",
    "     np.array([3.0, 6.0]),\n",
    "     np.array([4.0, 5.0])),\n",
    "\n",
    "    # laplace centered at 4 with scale 1 in both dims\n",
    "    (\"laplace\",\n",
    "     np.array([4.0, 4.0]),\n",
    "     np.array([1.0, 1.0])),\n",
    "\n",
    "    # normal centered at -5 with std 3 in both dims\n",
    "    (\"normal\",\n",
    "     np.array([-5.0, -5.0]),\n",
    "     np.array([3.0, 3.0])),\n",
    "\n",
    "    # exponential with scale=1 in both dims, then shifted by -5\n",
    "    (\"exponential\",\n",
    "     np.array([1.0, 1.0]),    # scale\n",
    "     np.array([-5.0, -5.0])), # shift\n",
    "]\n",
    "\n",
    "weights = [0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.1]\n",
    "\n",
    "data = get_mixture_distribution(mixture_list, weights, size=(100000, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9708e170",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.plots.plot_3d_kde(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a0072f",
   "metadata": {},
   "source": [
    "# Train GMMN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306cddc9",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753bcbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./model_weights\"\n",
    "\n",
    "ENCODER_SAVE_PATH = model_dir + \"/autoencoder.pth\"\n",
    "GMMN_SAVE_PATH = model_dir + \"/gmmn.pth\"\n",
    "\n",
    "BATCH_SIZE = 1000 # taken from original paper\n",
    "trainloader, testloader = load_MNIST1D(batch_size = BATCH_SIZE)\n",
    "# trainloader, testloader = load_MNIST(batch_size = BATCH_SIZE, size=7, flatten=True)\n",
    "N_INP = next(iter(trainloader))[0].shape[2]\n",
    "NOISE_SIZE = 10\n",
    "ENCODED_SIZE = N_INP // 2\n",
    "N_ENCODER_EPOCHS = 2000\n",
    "N_GEN_EPOCHS = 2000\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1b952c",
   "metadata": {},
   "source": [
    "## Train Autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd2da85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.gmmn.train_autoencoder import train_autoencoder\n",
    "from visualization.loss import plot_loss\n",
    "\n",
    "autoencoder, losses_autoencoder = train_autoencoder(trainloader, N_INP, ENCODED_SIZE, N_ENCODER_EPOCHS, device, ENCODER_SAVE_PATH)\n",
    "plot_loss(losses_autoencoder, title=\"Autoencoder Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda99ece",
   "metadata": {},
   "source": [
    "## Continue with GMMN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9c6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.gmmn.train_gmmn import train_gmmn\n",
    "from visualization import loss\n",
    "\n",
    "gmm_net, losses_gmmn = train_gmmn(trainloader, autoencoder, ENCODED_SIZE, NOISE_SIZE, BATCH_SIZE, N_GEN_EPOCHS, device, GMMN_SAVE_PATH)\n",
    "plot_loss(losses_gmmn, title=\"GMMN Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd81914",
   "metadata": {},
   "source": [
    "## Sample Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.gmmn.gmmn import generate_gmmn_samples\n",
    "from visualization.visualize_1d_data import visualize_mnist1d\n",
    "\n",
    "samples, labels = next(iter(trainloader))\n",
    "visualize_mnist1d(samples, labels, title=\"Real\")\n",
    "gen_samples = generate_gmmn_samples(gmm_net, autoencoder, NOISE_SIZE, 5)\n",
    "visualize_mnist1d(gen_samples, labels, title=\"Generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95125da7",
   "metadata": {},
   "source": [
    "## Bootstrapping Hypothesis Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.bootstrapping_test import bootstrap_hypothesis_test\n",
    "\n",
    "original_data = []\n",
    "for batch_idx, (data, labels) in enumerate(trainloader):\n",
    "    original_data.append(data.cpu()) # .cpu() if data is on GPU\n",
    "original_data = torch.cat(original_data, dim=0)\n",
    "original_data = np.squeeze(original_data.numpy())\n",
    "generating_function = generate_gmmn_samples\n",
    "gen_args = (gmm_net, autoencoder, NOISE_SIZE, 20000)\n",
    "alpha = 0.05\n",
    "num_iterations = 1000\n",
    "\n",
    "bootstrap_hypothesis_test(original_data, generating_function, gen_args, alpha, num_iterations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
